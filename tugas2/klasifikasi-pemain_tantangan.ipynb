{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11453059,"sourceType":"datasetVersion","datasetId":7176102}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:09.777313Z","iopub.execute_input":"2025-04-19T04:23:09.777675Z","iopub.status.idle":"2025-04-19T04:23:14.451981Z","shell.execute_reply.started":"2025-04-19T04:23:09.777644Z","shell.execute_reply":"2025-04-19T04:23:14.450945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndata_dir = \"/kaggle/input/player-teams-classification/dataset_pemain\"\nimage_size = 224\nbatch_size = 32\nnum_epochs = 50\npatience = 40\ncheckpoint_path = \"best_mobilenetv2_model.pth\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:14.453558Z","iopub.execute_input":"2025-04-19T04:23:14.453983Z","iopub.status.idle":"2025-04-19T04:23:14.460952Z","shell.execute_reply.started":"2025-04-19T04:23:14.453957Z","shell.execute_reply":"2025-04-19T04:23:14.459774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    \n    # Rotasi ekstrim dan mirror\n    transforms.RandomHorizontalFlip(p=1.0),\n    transforms.RandomVerticalFlip(p=0.7),\n    transforms.RandomRotation(degrees=90),\n    \n    # Distorsi geometris dan skala ekstrem\n    transforms.RandomAffine(\n        degrees=60,\n        translate=(0.3, 0.3),\n        scale=(0.5, 1.5),\n        shear=45\n    ),\n    \n    # Warna benar-benar diacak\n    transforms.ColorJitter(\n        brightness=0.8,\n        contrast=0.8,\n        saturation=0.8,\n        hue=0.3\n    ),\n    \n    # Blur dan noise\n    transforms.GaussianBlur(kernel_size=(7, 7), sigma=(2.0, 5.0)),\n    transforms.RandomGrayscale(p=1.0),\n    \n    # Konversi ke tensor dan normalisasi\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n\ndataset = datasets.ImageFolder(root=data_dir, transform=transform)\nclass_names = dataset.classes\nnum_classes = len(class_names)\n\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n    dataset, [train_size, val_size, test_size]\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:14.461880Z","iopub.execute_input":"2025-04-19T04:23:14.462262Z","iopub.status.idle":"2025-04-19T04:23:15.014445Z","shell.execute_reply.started":"2025-04-19T04:23:14.462233Z","shell.execute_reply":"2025-04-19T04:23:15.013663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = models.mobilenet_v2(pretrained=True)\nmodel.classifier[1] = nn.Linear(model.last_channel, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:15.015329Z","iopub.execute_input":"2025-04-19T04:23:15.015640Z","iopub.status.idle":"2025-04-19T04:23:15.146874Z","shell.execute_reply.started":"2025-04-19T04:23:15.015617Z","shell.execute_reply":"2025-04-19T04:23:15.145874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Train samples: {len(train_dataset)}\")\nprint(f\"Val samples: {len(val_dataset)}\")\nprint(f\"Test samples: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:15.149058Z","iopub.execute_input":"2025-04-19T04:23:15.149337Z","iopub.status.idle":"2025-04-19T04:23:15.154040Z","shell.execute_reply.started":"2025-04-19T04:23:15.149314Z","shell.execute_reply":"2025-04-19T04:23:15.152998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nbest_val_loss = float('inf')\npatience_counter = 0\n\ntrain_acc_history, val_acc_history = [], []\ntrain_loss_history, val_loss_history = [], []\nepoch_times = []\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n\n    # Training\n    model.train()\n    train_loss, train_correct = 0.0, 0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        train_correct += (preds == labels).sum().item()\n\n    train_acc = train_correct / len(train_dataset)\n    train_loss_avg = train_loss / len(train_loader)\n\n    # Validation\n    model.eval()\n    val_loss, val_correct = 0.0, 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n\n    val_acc = val_correct / len(val_dataset)\n    val_loss_avg = val_loss / len(val_loader)\n\n    # Logging\n    train_acc_history.append(train_acc)\n    val_acc_history.append(val_acc)\n    train_loss_history.append(train_loss_avg)\n    val_loss_history.append(val_loss_avg)\n\n    elapsed_time = time.time() - start_time\n    epoch_times.append(elapsed_time)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | \"\n          f\"Train Loss: {train_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f} | \"\n          f\"Time: {elapsed_time:.2f}s\")\n\n    # Early stopping\n    if val_loss_avg < best_val_loss:\n        best_val_loss = val_loss_avg\n        patience_counter = 0\n        print(\"âœ… Validation loss improved.\")\n    else:\n        patience_counter += 1\n        print(f\"âš ï¸No improvement. Patience: {patience_counter}/{patience}\")\n        if patience_counter >= patience:\n            print(\"â›” Early stopping triggered!\")\n            break\n\n# Setelah loop selesai\navg_epoch_time = sum(epoch_times) / len(epoch_times)\nprint(f\"\\nðŸ“Š Rata-rata waktu per epoch: {avg_epoch_time:.2f} detik\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:23:15.154865Z","iopub.execute_input":"2025-04-19T04:23:15.155153Z","iopub.status.idle":"2025-04-19T06:07:09.718568Z","shell.execute_reply.started":"2025-04-19T04:23:15.155123Z","shell.execute_reply":"2025-04-19T06:07:09.717305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\ny_true, y_pred = [], []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        y_true.extend(labels.numpy())\n        y_pred.extend(preds.cpu().numpy())\n\nprint(classification_report(y_true, y_pred, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:07:09.719988Z","iopub.execute_input":"2025-04-19T06:07:09.720409Z","iopub.status.idle":"2025-04-19T06:07:19.794816Z","shell.execute_reply.started":"2025-04-19T06:07:09.720352Z","shell.execute_reply":"2025-04-19T06:07:19.793814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nplt.subplot(1,2,1)\nplt.plot(train_loss_history, label='Train Loss')\nplt.plot(val_loss_history, label='Val Loss')\nplt.title('Loss per Epoch')\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(train_acc_history, label='Train Accuracy')\nplt.plot(val_acc_history, label='Val Accuracy')\nplt.title('Accuracy per Epoch')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:07:19.795828Z","iopub.execute_input":"2025-04-19T06:07:19.796185Z","iopub.status.idle":"2025-04-19T06:07:20.239661Z","shell.execute_reply.started":"2025-04-19T06:07:19.796054Z","shell.execute_reply":"2025-04-19T06:07:20.238569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(train_loss_history, label='Train Loss')\nplt.plot(val_loss_history, label='Val Loss')\nplt.legend()\nplt.title('Loss per Epoch')\n\nplt.subplot(1,2,2)\nplt.plot(train_acc_history, label='Train Accuracy')\nplt.plot(val_acc_history, label='Val Accuracy')\nplt.legend()\nplt.title('Accuracy per Epoch')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:07:20.240735Z","iopub.execute_input":"2025-04-19T06:07:20.241107Z","iopub.status.idle":"2025-04-19T06:07:20.660836Z","shell.execute_reply.started":"2025-04-19T06:07:20.241070Z","shell.execute_reply":"2025-04-19T06:07:20.659811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n# Pastikan model dalam mode evaluasi\nmodel.eval()\n\n# Untuk menyimpan hasil\ny_true = []\ny_pred = []\n\n# Jangan hitung gradien saat evaluasi (hemat memori dan lebih cepat)\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\n# Hitung akurasi\naccuracy = np.mean(np.array(y_true) == np.array(y_pred))\nprint(f\"Akurasi pada test set: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:07:20.661608Z","iopub.execute_input":"2025-04-19T06:07:20.661855Z","iopub.status.idle":"2025-04-19T06:07:30.762281Z","shell.execute_reply.started":"2025-04-19T06:07:20.661835Z","shell.execute_reply":"2025-04-19T06:07:30.761418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Tampilkan confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Print classification report (precision, recall, f1-score)\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:07:30.763390Z","iopub.execute_input":"2025-04-19T06:07:30.763671Z","iopub.status.idle":"2025-04-19T06:07:31.009436Z","shell.execute_reply.started":"2025-04-19T06:07:30.763648Z","shell.execute_reply":"2025-04-19T06:07:31.008343Z"}},"outputs":[],"execution_count":null}]}